{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqjjt9nhgHJH"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.linalg import svd\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    models,\n",
        "    layers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "7C4u_7XQl7wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_data = np.load('drive/MyDrive/collab_data/music_data.npy') # 10500x30x79\n",
        "other_data = np.load('drive/MyDrive/collab_data/other_data.npy') # 10500x30x79\n",
        "num_samples = music_data.shape[0]\n",
        "time_frames = music_data.shape[2]"
      ],
      "metadata": {
        "id": "MCck6Vk1l97S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add labels and combine the data"
      ],
      "metadata": {
        "id": "k2bn8aKMssMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((music_data, other_data), axis=0)\n",
        "y = np.array([1]*num_samples + [0]*num_samples)\n",
        "\n",
        "X30 = X[..., :30]\n",
        "X10 = X[..., :10]\n",
        "X20 = X[..., :20]\n",
        "\n",
        "def accuracy_score(true, pred):\n",
        "  return np.mean(true == pred)\n"
      ],
      "metadata": {
        "id": "MK0_aIRksyVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA"
      ],
      "metadata": {
        "id": "_7aPTXLKGZ-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XPCA = np.empty((X.shape[0], 10, 79))\n",
        "for i, x in enumerate(X):\n",
        "  U, S, Vh = np.linalg.svd(x, full_matrices=False)\n",
        "  V = Vh.T\n",
        "  Z = x.T @ U[:, :10]\n",
        "  XPCA[i] = Z.T"
      ],
      "metadata": {
        "id": "xvYQK7x0Ga_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ANN for sample classification"
      ],
      "metadata": {
        "id": "gif-NdGFy_ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrices = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "for x in [X]:#[X, X30, X20, X10, XPCA]:\n",
        "  print('='*20 + f' Training model for {x.shape[2]} timeframes per sample ' + '='*20)\n",
        "  ann = models.Sequential()\n",
        "  ann.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*x[0].shape, 1)))\n",
        "  ann.add(layers.MaxPooling2D((2, 2)))\n",
        "  ann.add(layers.Dropout(0.2))\n",
        "  ann.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*x[0].shape, 1)))\n",
        "  ann.add(layers.MaxPooling2D((2, 2)))\n",
        "  ann.add(layers.Dropout(0.2))\n",
        "  ann.add(layers.Flatten())\n",
        "  ann.add(layers.Dense(64, activation='relu'))\n",
        "  ann.add(layers.Dropout(0.2))\n",
        "  ann.add(layers.Dense(32, activation='relu'))\n",
        "  ann.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "  ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, stratify=y, random_state=123)\n",
        "  X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
        "\n",
        "  history = ann.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), callbacks=[callback])\n",
        "\n",
        "  y_pred = ann.predict(X_test) > 0.5\n",
        "  cf_matrices.append(confusion_matrix(y_pred, y_test))\n",
        "  accuracy = accuracy_score(y_test, y_pred[:, 0])\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  print(f'Accuracy: {accuracy:3.3f}')\n",
        "  print(f'Precision: {precision:3.3f}')\n",
        "  print(f'Recall: {recall:3.3f}')\n",
        "  print(f'F1 Score: {f1:3.3f}')\n",
        "  accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "2D4BGKg_zCyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4cd3dd-4d35-4004-ab41-8362a92d0b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Training model for 79 timeframes per sample ====================\n",
            "Epoch 1/20\n",
            "420/420 [==============================] - 6s 13ms/step - loss: 0.4296 - accuracy: 0.7978 - val_loss: 0.1796 - val_accuracy: 0.9426\n",
            "Epoch 2/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.1515 - accuracy: 0.9457 - val_loss: 0.1077 - val_accuracy: 0.9616\n",
            "Epoch 3/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.1064 - accuracy: 0.9632 - val_loss: 0.0744 - val_accuracy: 0.9744\n",
            "Epoch 4/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.0788 - accuracy: 0.9721 - val_loss: 0.1004 - val_accuracy: 0.9634\n",
            "Epoch 5/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.0716 - accuracy: 0.9733 - val_loss: 0.0556 - val_accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "420/420 [==============================] - 5s 11ms/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 0.0369 - val_accuracy: 0.9872\n",
            "Epoch 7/20\n",
            "420/420 [==============================] - 5s 13ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 0.0291 - val_accuracy: 0.9914\n",
            "Epoch 8/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.0481 - accuracy: 0.9830 - val_loss: 0.0425 - val_accuracy: 0.9863\n",
            "Epoch 9/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 0.0317 - val_accuracy: 0.9896\n",
            "Epoch 10/20\n",
            "420/420 [==============================] - 5s 12ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0454 - val_accuracy: 0.9818\n",
            "Accuracy: 0.983\n",
            "Precision: 0.997\n",
            "Recall: 0.969\n",
            "F1 Score: 0.983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(X_val.shape)\n",
        " ann.predict(X_test[0, None])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoPc5d5Lr-6m",
        "outputId": "1e384c50-973b-4f1d-dcae-a6313fd23af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3360, 30, 79)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.981402]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in cf_matrices:\n",
        "  print(m)\n",
        "\n",
        "print(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikaLMIYp7jgA",
        "outputId": "58c40f05-8dac-41b3-bf37-7d06a1374598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2094   65]\n",
            " [   6 2035]]\n",
            "[0.9830952380952381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.io.pickle import to_pickle\n",
        "import pandas as pd\n",
        "from time import perf_counter\n",
        "\n",
        "test_data = np.load('drive/MyDrive/collab_data/test_data.npy')\n",
        "tic = perf_counter()\n",
        "for _ in range(100):\n",
        "  test_predict = ann.predict(test_data)\n",
        "# df = pd.DataFrame(test_predict, columns=['prediction'])\n",
        "# df.to_csv('sound_classified.csv')\n",
        "toc = perf_counter()\n",
        "print((toc-tic)/100)\n",
        "\n",
        "ann.save('cnn.h5', save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabF2sp0uQy9",
        "outputId": "2d81b13b-c826-45fb-9248-44ad48d6de2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5483554661500011\n"
          ]
        }
      ]
    }
  ]
}